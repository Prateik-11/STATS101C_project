{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gj2_1GMxAIIE"
   },
   "source": [
    "# Text classification with CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3AfrBrP3LYsh",
    "outputId": "147f2240-3b72-4952-a573-76d06488945a"
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "_1VGpsdNL__r"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 0.418 0.24968 -0.41242 0.1217 0.34527 -0.044457 -0.49688 -0.17862 -0.00066023 -0.6566 0.27843 -0.14767 -0.55677 0.14658 -0.0095095 0.011658 0.10204 -0.12792 -0.8443 -0.12181 -0.016801 -0.33279 -0.1552 -0.23131 -0.19181 -1.8823 -0.76746 0.099051 -0.42125 -0.19526 4.0071 -0.18594 -0.52287 -0.31681 0.00059213 0.0074449 0.17778 -0.15897 0.012041 -0.054223 -0.29871 -0.15749 -0.34758 -0.045637 -0.44251 0.18785 0.0027849 -0.18411 -0.11514 -0.78581\n"
     ]
    }
   ],
   "source": [
    "vocab,embeddings = [],[]\n",
    "\n",
    "with open('/Users/juliabi2020/Desktop/ECE_C147_project/glove/glove.6B.50d.txt','rt', encoding=\"utf8\") as fi:\n",
    "    full_content = fi.read() # read the file\n",
    "    full_content = full_content.strip() # remove leading and trailing whitespace\n",
    "    full_content = full_content.split('\\n') # split the text into a list of lines\n",
    "\n",
    "for i in range(len(full_content)):\n",
    "    i_word = full_content[i].split(' ')[0] # get the word at the start of the line\n",
    "    i_embeddings = [float(val) for val in full_content[i].split(' ')[1:]] # get the embedding of the word in an array\n",
    "    # add the word and the embedding to our lists\n",
    "    vocab.append(i_word)\n",
    "    embeddings.append(i_embeddings)\n",
    "\n",
    "# convert our lists to numpy arrays:\n",
    "import numpy as np\n",
    "vocab_npa = np.array(vocab)\n",
    "embs_npa = np.array(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fdbkn8wuRBbR",
    "outputId": "b0f36d72-9d28-477e-85e8-983d5b8be9e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<pad>' '<unk>' 'the' ',' '.' 'of' 'to' 'and' 'in' 'a']\n",
      "(400002, 50)\n"
     ]
    }
   ],
   "source": [
    "# insert tokens for padding and unknown words into our vocab\n",
    "vocab_npa = np.insert(vocab_npa, 0, '<pad>')\n",
    "vocab_npa = np.insert(vocab_npa, 1, '<unk>')\n",
    "print(vocab_npa[:10])\n",
    "\n",
    "# make embeddings for these 2:\n",
    "# -> for the '<pad>' token, we set it to all zeros\n",
    "# -> for the '<unk>' token, we set it to the mean of all our other embeddings\n",
    "\n",
    "pad_emb_npa = np.zeros((1, embs_npa.shape[1])) \n",
    "unk_emb_npa = np.mean(embs_npa, axis=0, keepdims=True) \n",
    "\n",
    "#insert embeddings for pad and unk tokens to embs_npa.\n",
    "embs_npa = np.vstack((pad_emb_npa,unk_emb_npa,embs_npa))\n",
    "print(embs_npa.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eBpGRxt0RGAB",
    "outputId": "6d25ba2a-74b0-40b1-a6b4-ca7649bbfdba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([400002, 50])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "my_embedding_layer = torch.nn.Embedding.from_pretrained(torch.from_numpy(embs_npa).float())\n",
    "\n",
    "# sanity check\n",
    "assert my_embedding_layer.weight.shape == embs_npa.shape\n",
    "print(my_embedding_layer.weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "RrHiL-35UIcZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# load train.csv into a pandas dataframe\n",
    "# we can use any other NLP binary classfication problem here as long as\n",
    "# there are only 2 columns: 'review' and 'label'\n",
    "# where review contains text and label contains 0/1\n",
    "\n",
    "df = pd.read_csv(\"/Users/juliabi2020/Desktop/ECE_C147_project/archive/yelp_review.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              review  label\n",
      "0  Super simple place but amazing nonetheless. It...      1\n",
      "1  Small unassuming place that changes their menu...      1\n",
      "2  Lester's is located in a beautiful neighborhoo...      1\n",
      "3  Love coming here. Yes the place always needs t...      1\n",
      "4  Had their chocolate almond croissant and it wa...      1\n"
     ]
    }
   ],
   "source": [
    "df_new = df.drop(columns = ['review_id', 'user_id', 'business_id', 'date', 'useful', 'funny', 'cool'])\n",
    "df_new['label'] = df_new.apply(lambda row: int(row.stars>=4), axis = 1)\n",
    "#1: 4 or 5 stars, 0: <4 stars\n",
    "df_new = df_new.drop(columns = ['stars'])\n",
    "df_new = df_new.rename(columns={\"text\": \"review\"})\n",
    "\n",
    "print(df_new.head())\n",
    "df = df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:       3683167 rows\n",
      "Test:        1052334 rows\n",
      "Validation:  526167 rows\n"
     ]
    }
   ],
   "source": [
    "train_prop = 0.7 # 70% for training set\n",
    "test_prop = 0.2 # 20% for test set\n",
    "val_prop = 0.1 # 10% for validation set\n",
    "\n",
    "# split the data into training and validation sets\n",
    "train_val_df, test_df = train_test_split(df, test_size=test_prop, shuffle=True, random_state=11)\n",
    "df, val_df = train_test_split(train_val_df, test_size=val_prop/(train_prop+val_prop), shuffle=True, random_state=11)\n",
    "\n",
    "# print the number of rows in each set\n",
    "print(f\"Train:       {len(df)} rows\")\n",
    "print(f\"Test:        {len(test_df)} rows\")\n",
    "print(f\"Validation:  {len(val_df)} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "zpk-qQSISpU4"
   },
   "outputs": [],
   "source": [
    "class CNNDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, df, vocab, max_seq_length, pad_token, unk_token):\n",
    "        # make a list of our labels\n",
    "        self.labels = df.label.tolist()\n",
    "\n",
    "        # make a dictionary converting each word to its id in the vocab, as well\n",
    "        # as the reverse lookup\n",
    "        self.word2idx = {term:idx for idx,term in enumerate(vocab)}\n",
    "        self.idx2word = {idx:word for word,idx in self.word2idx.items()} \n",
    "        \n",
    "        self.pad_token,self.unk_token = pad_token,unk_token\n",
    "\n",
    "        self.input_ids = [] \n",
    "        self.sequence_lens = [] \n",
    "        self.labels = []\n",
    "\n",
    "        for i in range(df.shape[0]):\n",
    "            # clean up each sentence and turn it into tensor containing the  \n",
    "            # token ids of each word. Also add padding to make them all the \n",
    "            # same length as the longest sequence\n",
    "            input_ids,sequence_len = self.convert_text_to_input_ids(\n",
    "                df.iloc[i].review,\n",
    "                pad_to_len = max_seq_length) \n",
    "            \n",
    "            self.input_ids.append(input_ids.reshape(-1))\n",
    "            self.sequence_lens.append(sequence_len)\n",
    "            self.labels.append(df.iloc[i].label)\n",
    "        \n",
    "        #sanity checks\n",
    "        assert len(self.input_ids) == df.shape[0]\n",
    "        assert len(self.sequence_lens) == df.shape[0]\n",
    "        assert len(self.labels) == df.shape[0]\n",
    "    \n",
    "    def convert_text_to_input_ids(self,text,pad_to_len):\n",
    "        # truncate excess words (beyond the length we should pad to)\n",
    "        words = text.strip().split()[:pad_to_len]\n",
    "\n",
    "        # add padding till we've reached desired length \n",
    "        deficit = pad_to_len - len(words) \n",
    "        words.extend([self.pad_token]*deficit)\n",
    "\n",
    "        # replace words with their id\n",
    "        for i in range(len(words)):\n",
    "            if words[i] not in self.word2idx:\n",
    "                # if word is not in vocab, then use <unk> token\n",
    "                words[i] = self.word2idx[self.unk_token] \n",
    "            else:\n",
    "                # else find the id associated with the word \n",
    "                words[i] = self.word2idx[words[i]] \n",
    "        return torch.Tensor(words).long(),pad_to_len - deficit\n",
    "\n",
    "    def __len__(self):\n",
    "        # Make dataset compatible with len() function\n",
    "        return len(self.input_ids)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        # for the ith indexm return a dictionary containing id, length and label\n",
    "        sample_dict = dict()\n",
    "        sample_dict['input_ids'] = self.input_ids[i].reshape(-1)\n",
    "        sample_dict['sequence_len'] = torch.tensor(self.sequence_lens[i]).long()\n",
    "        sample_dict['labels'] = torch.tensor(self.labels[i]).type(torch.FloatTensor)\n",
    "        return sample_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "DHHgjpseZKXq"
   },
   "outputs": [],
   "source": [
    "class CNNEncoder(torch.nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(CNNEncoder, self).__init__()\n",
    "        \n",
    "        # use the pretrained embeddings and check whether or not we should\n",
    "        # freeze embeddings from our config dict\n",
    "        pretrained_embeddings = config['pretrained_embeddings'] if 'pretrained_embeddings' in config else None\n",
    "        freeze_embeddings = config['freeze_embeddings'] if 'freeze_embeddings' in config else False\n",
    "        if pretrained_embeddings is not None:\n",
    "            # use pretrained embeddings\n",
    "            self.vocab_size = pretrained_embeddings.shape[0]\n",
    "            self.embedding_dim = pretrained_embeddings.shape[1]\n",
    "            self.embedding = torch.nn.Embedding.from_pretrained(\n",
    "                torch.from_numpy(pretrained_embeddings).float(),\n",
    "                freeze=freeze_embeddings\n",
    "                )\n",
    "        else:\n",
    "            # use randomly initialized embeddings\n",
    "            assert 'vocab' in config and 'embedding_dim' in config\n",
    "            self.vocab_size = config['vocab'].shape[0]\n",
    "            self.embedding_dim = config['embedding_dim']\n",
    "            if freeze_embeddings:\n",
    "                # why would you do this?\n",
    "                print(\n",
    "                    'WARNING:Freezing Randomly Initialized Embeddings!!ðŸ˜­ðŸ˜­ðŸ˜­'\n",
    "                    )\n",
    "            self.embedding = torch.nn.Embedding(\n",
    "                self.vocab_size,\n",
    "                self.embedding_dim,\n",
    "                freeze = freeze_embeddings\n",
    "                )\n",
    "        self.kernel_size = 93\n",
    "        self.out_channels = 32\n",
    "        \n",
    "        # store some values from the config \n",
    "        self.hidden_size = config['hidden_size']\n",
    "\n",
    "        self.cnn = torch.nn.Conv1d(\n",
    "            in_channels = self.embedding_dim,\n",
    "            out_channels = self.out_channels,\n",
    "            kernel_size = self.kernel_size\n",
    "            )\n",
    "        \n",
    "        middle_nodes = int(self.hidden_size / 2)\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(in_features = self.hidden_size, out_features = middle_nodes)\n",
    "        self.fc2 = torch.nn.Linear(in_features = middle_nodes, out_features = 1)\n",
    "        self.relu = torch.nn.functional.relu\n",
    "        self.sigmoid = torch.nn.Sigmoid()\n",
    "\n",
    "    def forward(self, batch):\n",
    "        x = batch['input_ids'].to(device) # lookup token ids for our inputs\n",
    "        x_lengths = batch['sequence_len'] # lookup lengths of our inputs\n",
    "        embed_out = self.embedding(x) # get the embeddings of the token ids\n",
    "\n",
    "        embed_out = embed_out.permute(0,2,1)\n",
    "        \n",
    "        cnn_out = self.cnn(embed_out)\n",
    "\n",
    "        m_flatten = nn.Flatten()\n",
    "        fc1_in = m_flatten(cnn_out)\n",
    "        \n",
    "        #in_features= self.hidden_size\n",
    "        fc1_out = self.fc1(fc1_in)\n",
    "        fc1_out = self.relu(fc1_out)\n",
    "        fc2_out = self.fc2(fc1_out)\n",
    "        final_out = self.sigmoid(fc2_out)\n",
    "        return final_out\n",
    "    \n",
    "    def get_embedding_dims(self):\n",
    "        return self.vocab_size, self.embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "xCVdov26beF4"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    #model configurations\n",
    "    'batch_size':32,\n",
    "    'max_seq_length':100,\n",
    "    'lr':1e-4,\n",
    "    'label_count':2,\n",
    "    'dropout_prob':2e-1,\n",
    "    'hidden_size':256,\n",
    "\n",
    "    #embeddings configurations\n",
    "    'pretrained_embeddings':embs_npa,\n",
    "    'freeze_embeddings':True,\n",
    "    'vocab':vocab_npa,\n",
    "    'pad_token':'<pad>',\n",
    "    'unk_token':'<unk>',\n",
    "\n",
    "    #data\n",
    "    'train_df': df, #TODO: set val and test to appropriate\n",
    "    'val_df': val_df,\n",
    "    'test_df': test_df,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "klDnR0Wxb03n"
   },
   "outputs": [],
   "source": [
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataset = CNNDataset(\n",
    "    df = config['train_df'], \n",
    "    vocab = config['vocab'],\n",
    "    max_seq_length = config['max_seq_length'],\n",
    "    pad_token = config['pad_token'],\n",
    "    unk_token = config['unk_token']\n",
    ")\n",
    "val_dataset = CNNDataset(\n",
    "    df = config['val_df'], \n",
    "    vocab = config['vocab'],\n",
    "    max_seq_length = config['max_seq_length'],\n",
    "    pad_token = config['pad_token'],\n",
    "    unk_token = config['unk_token']\n",
    ")\n",
    "test_dataset = CNNDataset(\n",
    "    df = config['test_df'], \n",
    "    vocab = config['vocab'],\n",
    "    max_seq_length = config['max_seq_length'],\n",
    "    pad_token = config['pad_token'],\n",
    "    unk_token = config['unk_token']\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size = config['batch_size'], shuffle = True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size = config['batch_size'], shuffle = True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size = config['batch_size'], shuffle = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = CNNEncoder(config)\n",
    "model.to(device)\n",
    "model.train()\n",
    "\n",
    "loss_criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = config['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "id": "x_bQcvNepZOu"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "def validation(model, val_loader):\n",
    "    with torch.no_grad():\n",
    "        all_outputs = []\n",
    "        all_labels = []\n",
    "        for data in val_loader:\n",
    "            labels = data['labels'].to(device)\n",
    "            outputs = model(data)\n",
    "            all_outputs = all_outputs + torch.round(outputs.squeeze()).tolist()\n",
    "            all_labels = all_labels + labels.tolist()\n",
    "        \n",
    "        accuracy = sum([i==j for i, j in zip(all_outputs, all_labels)]) / len(all_labels)\n",
    "        f1 = f1_score(y_pred= all_outputs, y_true=all_labels)\n",
    "\n",
    "        return accuracy, f1\n",
    "\n",
    "def testing(model, test_loader):\n",
    "    with torch.no_grad():\n",
    "        all_outputs = []\n",
    "        all_labels = []\n",
    "        all_scores = []\n",
    "        for data in test_loader:\n",
    "            labels = data['labels'].to(device)\n",
    "            outputs = model(data)\n",
    "            all_scores = all_scores + (outputs.squeeze()).tolist()\n",
    "            all_outputs = all_outputs + torch.round(outputs.squeeze()).tolist()\n",
    "            all_labels = all_labels + labels.tolist()\n",
    "        accuracy = sum([i==j for i, j in zip(all_outputs, all_labels)]) / len(all_labels)\n",
    "        f1 = f1_score(y_pred= all_outputs, y_true=all_labels)\n",
    "        roc = roc_auc_score(y_score= all_scores, y_true=all_labels)\n",
    "        cm = confusion_matrix(all_labels, all_outputs)\n",
    "        disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "        disp.plot(cmap = 'magma')\n",
    "        plt.show()\n",
    "        print('Test Statistics:')\n",
    "        print()\n",
    "        print(f\"Accuracy     : {accuracy}\")\n",
    "        print(f\"F1 score     : {f1}\")\n",
    "        print(f\"AUC ROC score: {roc}\")\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "s8VhpNQdoQKV"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=115099.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n",
      "Training   | Loss: 0.4509 | Accuracy: 0.78% \n",
      "Validation | F1:   0.8466 | Accuracy: 0.78% \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=115099.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2\n",
      "Training   | Loss: 0.4423 | Accuracy: 0.79% \n",
      "Validation | F1:   0.8461 | Accuracy: 0.79% \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=115099.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3\n",
      "Training   | Loss: 0.4364 | Accuracy: 0.79% \n",
      "Validation | F1:   0.8480 | Accuracy: 0.79% \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=115099.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4\n",
      "Training   | Loss: 0.4318 | Accuracy: 0.79% \n",
      "Validation | F1:   0.8497 | Accuracy: 0.79% \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=115099.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5\n",
      "Training   | Loss: 0.4280 | Accuracy: 0.80% \n",
      "Validation | F1:   0.8455 | Accuracy: 0.79% \n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(1, epochs + 1):\n",
    "  progress_bar = tqdm(train_dataloader, leave=False)\n",
    "  losses = []\n",
    "  accuracies = []\n",
    "  total = 0\n",
    "  for data in progress_bar:\n",
    "    target = data['labels'].to(device)\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data)\n",
    "    \n",
    "    #print(output.shape)\n",
    "    #print(target.shape)\n",
    "    \n",
    "    loss = loss_criterion(output.squeeze(), target)\n",
    "    \n",
    "    loss.backward()\n",
    "    # torch.nn.utils.clip_grad_norm_(model.parameters(), 3)\n",
    "    optimizer.step()\n",
    "    accuracy = torch.sum(target == torch.round(output.squeeze())) / target.shape[0]\n",
    "\n",
    "    losses.append(loss.item())\n",
    "    accuracies.append(accuracy.item())\n",
    "    total += 1\n",
    "\n",
    "    progress_bar.set_description(f'Loss: {loss.item():.3f}, Train Accuracy: {accuracy:.3f}')\n",
    "  \n",
    "  val_accuracy, val_f1 = validation(model, val_dataloader)\n",
    "  print(f'Epoch: {epoch}')\n",
    "  print(f'Training   | Loss: {(sum(losses) / total):.4f} | Accuracy: {(sum(accuracies) / total):.2f}% ')\n",
    "  print(f'Validation | F1:   {val_f1:.4f} | Accuracy: {val_accuracy:.2f}% ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oX-i1DiOc_SG"
   },
   "source": [
    "Now we will test our model using the test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "17VkY0uscvnV"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistics:\n",
      "\n",
      "Accuracy     : 0.7907784030545435\n",
      "F1 score     : 0.8455359842625196\n",
      "AUC ROC score: 0.8559384051573886\n"
     ]
    }
   ],
   "source": [
    "testing(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "f96c0a065a6f038b4d81e02ec5e62503dd3b71442db074018719e130d8db16de"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
